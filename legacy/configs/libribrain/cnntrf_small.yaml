in_channels: 306
channel_dropout_p: 0.5  # 0.5
lstm_dropout: 0.2  # 0.2
conv_dropout: 0.2  # 0.2
head_dropout: 0.0  # 0.0

hidden_channels: [512, 512, 512]  # [256, 512]
kernels: [5, 5, 5]  # [3, 3]
strides: [2, 2, 2]  # [1, 2]
norm: group  # group
ch_attn: null  # null

head_inputs: 512  # if flatten, this is the number of channels * sequence length
pooling: last  # last
num_classes: 39
k_conditioning: false

lstm_num_layers: 0  # 0
num_trf_blocks: 2  # 8

attn_args:
  d_model: 512
  nheads: 8  # 8
  dropout: 0.2  # 0.2
  rope: true

mlp_type: standard  # standard
mlp_args:
  d_model: 512
  # num_experts: 8
  # experts_per_token: 2
