save_dir: /vol/data/trainings/omega/1to50hz/ibq
resume_from: null

model_name: IBQMEGTokenizer
loss_name: VQLPIPSWithDiscriminator
model_config: configs/ibq/tokenizer.yaml

datasplitter:
  dataset_class: ChunkDatasetInterpolatedImage
  dataset_root: /vol/data/datasets/omega/full/1to50hz_cont
  example_seconds: 10.24
  overlap_seconds: 0.0
  val_ratio: 0.1
  test_ratio: 0.1
  refresh_cache: false  # need to refresh if any datasplitter args change
  cache_dir: /vol/data/datasets/omega/full/cache/1to50hz_cont_10.24s
  dataset_kwargs:
    image_size: 32
    sigma_scale: 0.75
    r_max_factor: 4.0

dataloader:
  batch_size: 1
  num_workers: 16
  prefetch_factor: 4
  pin_memory: true
  persistent_workers: true

lightning:
  lr: 1.0e-3
  weight_decay: 0.0
  betas: [0.5, 0.9]

loss:
  codebook_weight: 1.0
  pixelloss_weight: 1.0
  disc_start: 100  # 5
  disc_num_layers: 3
  disc_in_channels: 3
  disc_factor: 0.0  # 1.0
  disc_weight: 0.0  # 1.0
  perceptual_weight: 0.0  # 0.5
  use_actnorm: false
  disc_ndf: 64
  disc_loss: hinge
  quant_loss_weight: 1.0
  entropy_loss_weight: 1.0

trainer:
  tune_batch_size: false
  overfit_batches: 10
  max_epochs: 100
  accelerator: cuda
  check_val_every_n_epoch: 100
  checkpoint_cadence_epochs: 100
  log_every_n_steps: 2000
  # precision: bf16-mixed
  early_stopping:
    monitor: val_loss
    patience: 100
