trf_class: Qwen2_5_Video
hidden_size: 192
vocab_size: 256
input_shape: [200, 68, 1]  # T, H, W

trf_args:
  intermediate_size: 768
  num_hidden_layers: 12  # 36 in 3B model
  num_attention_heads: 8
  num_key_value_heads: 2
  attention_dropout: 0.0
  
  max_position_embeddings: 16384  # should be higher than T' x H' x W'
  rope_theta: 5000000.0
  rope_scaling:  # can experiment with different types
    type: default
    mrope_section: 4

  _attn_implementation: sdpa
  block_size: 1