num_channels: 68
vocab_size: 256
d_model: 1088
num_layers: 16  # 12
channel_dropout_p: 0.0
quant_emb: 16  # 8
attn_type: standard
mlp_type: standard

embedding_args:
  class_emb: 16
  num_classes: 6

attn_args:
  d_model: 1088
  nheads: 16  # 16
  dropout: 0.0
  rope: true

mlp_args:
  d_model: 1088
  # num_experts: 8
  # experts_per_token: 1