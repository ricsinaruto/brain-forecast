save_dir: /vol/data/trainings/omega/2sub/1to50hz/vidtok
resume_from: null

model_config: configs/vidtok/model888_32k.yaml

datasplitter:
  dataset_class: ChunkDatasetInterpolatedImage
  dataset_root: /vol/data/datasets/omega/2sub/1to50hz_cont
  example_seconds: 10.24
  overlap_seconds: 0.0
  val_ratio: 0.1
  test_ratio: 0.1
  # refresh_cache: false  # need to refresh if any datasplitter args change
  # cache_dir: /vol/data/datasets/omega/full/cache/1to50hz_cont_10.24s
  dataset_kwargs:
    image_size: 32  # 32
    sigma_scale: 0.75  # 0.75
    r_max_factor: 4.0  # 4.0

dataloader:
  batch_size: 2
  num_workers: 16
  prefetch_factor: 4
  pin_memory: true
  persistent_workers: true

loss:
  dims: 3  # video - [t,h,w]
  perceptual_weight: 0.0  # 1.0, could enable later as a regularization term
  disc_start: 201  # 20001, start of discriminator training
  disc_weight: 0.2
  disc_type: 3d  # 2d, 3d
  learn_logvar: true
  gen_loss_cross_entropy: true  
  lecam_loss_weight: 0.005
  regularization_weights: {'aux_loss': 1.0, 'kl_loss': 0.000001}
  temporal_pcc_weight: 1.0
  temporal_freq_amp_weight: 1.0
  temporal_freq_phase_weight: 0.5

lightning:
  lr: 1.0e-5
  ema_decay: null
  compile: false
  optimizer:
    target: torch.optim.AdamW
    params:
      weight_decay: 0.0

eval_runner:
  enabled: true
  use_modal: true
  modal_app: ephys-gpt
  modal_function: runevals
  max_batches: 10
  num_examples: 5
  lit_module: VidtokLightning

trainer:
  tune_batch_size: false
  max_epochs: 200
  accelerator: cuda
  check_val_every_n_epoch: 1
  checkpoint_cadence_epochs: 1
  log_every_n_steps: 10
  precision: bf16-mixed
  early_stopping:
    monitor: val_loss
    patience: 10